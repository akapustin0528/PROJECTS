{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dcbdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic packages for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3e74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_set = pd.read_csv('C:/Users/nasqi/Downloads/cleanedData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4795b72",
   "metadata": {},
   "source": [
    "Use forward and backward selection method to determine the best linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af13892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X_train, y_train, significance_level=0.05):\n",
    "    # Start with no predictors\n",
    "    initial_features = X_train.columns.tolist()\n",
    "    best_features = []\n",
    "    \n",
    "    while len(initial_features) > 0:  # Iterate over the set of all features\n",
    "        remaining_features = list(set(initial_features) - set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        \n",
    "        for new_column in remaining_features: # Iterate over the remaining features not yet included\n",
    "            # Fit model with the selected features and one additional feature\n",
    "            model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train[best_features + [new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        \n",
    "        min_p_value = new_pval.min()\n",
    "        if min_p_value < significance_level: # If the p-value is below the significance level, add it to the best features\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_features, len(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ae968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(X_train, y_train, significance_level=0.05):\n",
    "    # Start with all predictors\n",
    "    features = X_train.columns.tolist()\n",
    "    \n",
    "    # Iterate as long as there are features to consider\n",
    "    while len(features) > 0:\n",
    "        features_with_constant = sm.add_constant(X_train[features])\n",
    "        p_values = sm.OLS(y_train, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        # If the max p-value is above the significance level, remove that feature\n",
    "        if max_p_value >= significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "            \n",
    "    return features, len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc80be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "# Define features and target\n",
    "features = clean_set.drop('airTemp', axis=1) # 11 variables\n",
    "target = clean_set['airTemp'] # predict air temperature\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=141)\n",
    "# 20% test data 80% training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd7d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features by forward selection: ['tPrec', 'dpTemp', 'windSp', 'lat', 'airHum', 'long', 'rad', 'prevHrMinTemp', 'atmosPStatn', 'date_time', 'windDir']\n",
      "Number of features selected: 11\n",
      "Selected features by backward elimination: ['tPrec', 'atmosPStatn', 'rad', 'dpTemp', 'prevHrMinTemp', 'airHum', 'windDir', 'windSp', 'lat', 'long', 'date_time']\n",
      "Number of features selected: 11\n"
     ]
    }
   ],
   "source": [
    "# Forward selection\n",
    "selected_features_forward, count_forward = forward_selection(X_train, y_train)\n",
    "print(\"Selected features by forward selection:\", selected_features_forward)\n",
    "print(\"Number of features selected:\", count_forward)\n",
    "\n",
    "# Backward elimination\n",
    "selected_features_backward, count_backward = backward_elimination(X_train, y_train)\n",
    "print(\"Selected features by backward elimination:\", selected_features_backward)\n",
    "print(\"Number of features selected:\", count_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77579880",
   "metadata": {},
   "source": [
    "The forward and backward stepwise selection methods are returning all 11 variables as significant, it suggests that each variable in our dataset might be contributing meaningfully to the prediction of air temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cbabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "add6febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal alpha level for ridge and lasso regression model\n",
    "def k_fold_cv(model, X_train, y_train):\n",
    "    # k-fold-cross validation to find optimal alpha level\n",
    "    folds = KFold(n_splits = 5, shuffle = True, random_state = 141)\n",
    "    # Range for parameters\n",
    "    parameters = {'alpha':[0.001, 0.01, 0.1, 0.2, 0.5, 1.0, 5.0, 10.0]}\n",
    "    model_cv = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'r2', cv = folds\n",
    "                           , return_train_score = True, verbose = 1)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    alpha = model_cv.best_params_\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f02efcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best alpha for Ridge Regression: {'alpha': 10.0}\n"
     ]
    }
   ],
   "source": [
    "Ridge_model = Ridge()\n",
    "optimal_alpha_ridge = k_fold_cv(Ridge_model, X_train, y_train)\n",
    "print(\"Best alpha for Ridge Regression:\", optimal_alpha_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b080f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best alpha for Lasso Regression: {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "Lasso_model = Lasso()\n",
    "optimal_alpha_lasso = k_fold_cv(Lasso_model, X_train, y_train)\n",
    "print(\"Best alpha for Lasso Regression:\", optimal_alpha_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "380561e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Initialize a ridge regression model\n",
    "ridge_model = Ridge(alpha = 10.0, random_state = 141)  \n",
    "\n",
    "# Initialize a lasso regression model\n",
    "lasso_model = Lasso(alpha = 0.001, random_state = 141)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c74e8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression\n",
    "linear_mse, linear_mae, linear_r2 = train_and_evaluate(linear_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Ridge Regression\n",
    "ridge_mse, ridge_mae, ridge_r2 = train_and_evaluate(ridge_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Lasso Regression\n",
    "lasso_mse, lasso_mae, lasso_r2 = train_and_evaluate(lasso_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c3ba952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 0.34643680583595826 MAE: 0.4366569177176155 R2: 0.9729379484547314\n",
      "Ridge Regression - MSE: 0.3464368072931789 MAE: 0.43665684204255084 R2: 0.9729379483409\n",
      "Lasso Regression - MSE: 0.3464401157547637 MAE: 0.43665132711169985 R2: 0.9729376898990819\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression - MSE:\", linear_mse, \"MAE:\", linear_mae, \"R2:\", linear_r2)\n",
    "print(\"Ridge Regression - MSE:\", ridge_mse, \"MAE:\", ridge_mae, \"R2:\", ridge_r2)\n",
    "print(\"Lasso Regression - MSE:\", lasso_mse, \"MAE:\", lasso_mae, \"R2:\", lasso_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53e2e9",
   "metadata": {},
   "source": [
    "#### Old conclusion when Ridge and Lasso model use alpha level = 1.0\n",
    "\n",
    "~~The MSE is lower for both Linear and Ridge Regression compared to Lasso Regression. A lower MSE indicates better performance, as it means the predictions are closer to the actual values.~~\n",
    "\n",
    "~~Similar to MSE, the MAE is lower for Linear and Ridge Regression compared to Lasso Regression. Lower MAE means the average magnitude of errors in the predictions is smaller.~~\n",
    "\n",
    "~~The R-squared value is a measure of how well the independent variables explain the variance in the dependent variable. Higher R-squared values indicate better model performance. Here, both Linear and Ridge Regression have higher R-squared values compared to Lasso Regression.~~\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51243eee",
   "metadata": {},
   "source": [
    "~~Linear and Ridge Regression are performing almost identically and significantly better than Lasso Regression for our dataset, as indicated by the lower MSE and MAE, and higher R-squared values.~~\n",
    "\n",
    "~~The similarity in performance between Linear and Ridge Regression suggests that the dataset might not have significant multicollinearity issues or that the effect of regularization in Ridge Regression is minimal at the chosen alpha value.~~\n",
    "\n",
    "~~Given these results, Linear or Ridge Regression may be the preferred model for this dataset.~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a08f0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a normalized model\n",
    "def train_and_evaluate_normalized(model, X_train, X_test, y_train, y_test):\n",
    "    # Normalized the data\n",
    "    std_scalar = StandardScaler()\n",
    "    std_scalar.fit(X_train)\n",
    "    X_train = std_scalar.transform(X_train)\n",
    "    X_test = std_scalar.transform(X_test)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc0d60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a linear regression model\n",
    "Nor_linear_model = LinearRegression()\n",
    "\n",
    "# Initialize a ridge regression model\n",
    "Nor_ridge_model = Ridge(alpha = 10.0, random_state = 141)  \n",
    "\n",
    "# Initialize a lasso regression model\n",
    "Nor_lasso_model = Lasso(alpha = 0.01, random_state = 141)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f017a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression\n",
    "Nor_linear_mse, Nor_linear_mae, Nor_linear_r2 = train_and_evaluate_normalized(Nor_linear_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Ridge Regression\n",
    "Nor_ridge_mse, Nor_ridge_mae, Nor_ridge_r2 = train_and_evaluate_normalized(Nor_ridge_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Lasso Regression\n",
    "Nor_lasso_mse, Nor_lasso_mae, Nor_lasso_r2 = train_and_evaluate_normalized(Nor_lasso_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7976b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Linear Regression - MSE: 0.34643680583595815 MAE: 0.43665691771761406 R2: 0.9729379484547314\n",
      "Normalized Ridge Regression - MSE: 0.3464368283036457 MAE: 0.4366584142695304 R2: 0.9729379466996588\n",
      "Normalized Lasso Regression - MSE: 0.34902787965287585 MAE: 0.44029984563396785 R2: 0.9727355456730125\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Linear Regression - MSE:\", Nor_linear_mse, \"MAE:\", Nor_linear_mae, \"R2:\", Nor_linear_r2)\n",
    "print(\"Normalized Ridge Regression - MSE:\", Nor_ridge_mse, \"MAE:\", Nor_ridge_mae, \"R2:\", Nor_ridge_r2)\n",
    "print(\"Normalized Lasso Regression - MSE:\", Nor_lasso_mse, \"MAE:\", Nor_lasso_mae, \"R2:\", Nor_lasso_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d034eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 0.34643680583595826 MAE: 0.4366569177176155 R2: 0.9729379484547314\n",
      "Ridge Regression - MSE: 0.3464368072931789 MAE: 0.43665684204255084 R2: 0.9729379483409\n",
      "Lasso Regression - MSE: 0.3464401157547637 MAE: 0.43665132711169985 R2: 0.9729376898990819\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression - MSE:\", linear_mse, \"MAE:\", linear_mae, \"R2:\", linear_r2)\n",
    "print(\"Ridge Regression - MSE:\", ridge_mse, \"MAE:\", ridge_mae, \"R2:\", ridge_r2)\n",
    "print(\"Lasso Regression - MSE:\", lasso_mse, \"MAE:\", lasso_mae, \"R2:\", lasso_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de21de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
