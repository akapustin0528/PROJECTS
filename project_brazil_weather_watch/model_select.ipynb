{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcbdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic packages for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3e74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_set = pd.read_csv('/path/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4795b72",
   "metadata": {},
   "source": [
    "Use forward and backward selection method to determine the best linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af13892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X_train, y_train, significance_level=0.05):\n",
    "    # Start with no predictors\n",
    "    initial_features = X_train.columns.tolist()\n",
    "    best_features = []\n",
    "    \n",
    "    while len(initial_features) > 0:  # Iterate over the set of all features\n",
    "        remaining_features = list(set(initial_features) - set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        \n",
    "        for new_column in remaining_features: # Iterate over the remaining features not yet included\n",
    "            # Fit model with the selected features and one additional feature\n",
    "            model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train[best_features + [new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        \n",
    "        min_p_value = new_pval.min()\n",
    "        if min_p_value < significance_level: # If the p-value is below the significance level, add it to the best features\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_features, len(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ae968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(X_train, y_train, significance_level=0.05):\n",
    "    # Start with all predictors\n",
    "    features = X_train.columns.tolist()\n",
    "    \n",
    "    # Iterate as long as there are features to consider\n",
    "    while len(features) > 0:\n",
    "        features_with_constant = sm.add_constant(X_train[features])\n",
    "        p_values = sm.OLS(y_train, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        # If the max p-value is above the significance level, remove that feature\n",
    "        if max_p_value >= significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "            \n",
    "    return features, len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc80be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "# Define features and target\n",
    "features = clean_set.drop('airTemp', axis=1) # 11 variables\n",
    "target = clean_set['airTemp'] # predict air temperature\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=141)\n",
    "# 20% test data 80% training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd7d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features by forward selection: ['atmosPStatn', 'tPrec', 'date_time', 'airHum', 'long', 'lat', 'windSp', 'rad', 'prevHrMinTemp', 'dpTemp', 'windDir']\n",
      "Number of features selected: 11\n",
      "Selected features by backward elimination: ['tPrec', 'atmosPStatn', 'rad', 'dpTemp', 'prevHrMinTemp', 'airHum', 'windDir', 'windSp', 'lat', 'long', 'date_time']\n",
      "Number of features selected: 11\n"
     ]
    }
   ],
   "source": [
    "# Forward selection\n",
    "selected_features_forward, count_forward = forward_selection(X_train, y_train)\n",
    "print(\"Selected features by forward selection:\", selected_features_forward)\n",
    "print(\"Number of features selected:\", count_forward)\n",
    "\n",
    "# Backward elimination\n",
    "selected_features_backward, count_backward = backward_elimination(X_train, y_train)\n",
    "print(\"Selected features by backward elimination:\", selected_features_backward)\n",
    "print(\"Number of features selected:\", count_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77579880",
   "metadata": {},
   "source": [
    "The forward and backward stepwise selection methods are returning all 11 variables as significant, it suggests that each variable in our dataset might be contributing meaningfully to the prediction of air temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cbabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380561e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Initialize a ridge regression model\n",
    "ridge_model = Ridge(alpha = 1.0, random_state = 141)  \n",
    "\n",
    "# Initialize a lasso regression model\n",
    "lasso_model = Lasso(alpha = 1.0, random_state = 141)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74e8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression\n",
    "linear_mse, linear_mae, linear_r2 = train_and_evaluate(linear_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Ridge Regression\n",
    "ridge_mse, ridge_mae, ridge_r2 = train_and_evaluate(ridge_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate Lasso Regression\n",
    "lasso_mse, lasso_mae, lasso_r2 = train_and_evaluate(lasso_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3ba952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 0.34643680583595826 MAE: 0.4366569177176155 R2: 0.9729379484547314\n",
      "Ridge Regression - MSE: 0.34643680598159887 MAE: 0.436656910150719 R2: 0.9729379484433546\n",
      "Lasso Regression - MSE: 0.5992948937419601 MAE: 0.5605001171396021 R2: 0.9531858364005911\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression - MSE:\", linear_mse, \"MAE:\", linear_mae, \"R2:\", linear_r2)\n",
    "print(\"Ridge Regression - MSE:\", ridge_mse, \"MAE:\", ridge_mae, \"R2:\", ridge_r2)\n",
    "print(\"Lasso Regression - MSE:\", lasso_mse, \"MAE:\", lasso_mae, \"R2:\", lasso_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53e2e9",
   "metadata": {},
   "source": [
    "The MSE is lower for both Linear and Ridge Regression compared to Lasso Regression. A lower MSE indicates better performance, as it means the predictions are closer to the actual values.\n",
    "\n",
    "Similar to MSE, the MAE is lower for Linear and Ridge Regression compared to Lasso Regression. Lower MAE means the average magnitude of errors in the predictions is smaller.\n",
    "\n",
    "The R-squared value is a measure of how well the independent variables explain the variance in the dependent variable. Higher R-squared values indicate better model performance. Here, both Linear and Ridge Regression have higher R-squared values compared to Lasso Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51243eee",
   "metadata": {},
   "source": [
    "Linear and Ridge Regression are performing almost identically and significantly better than Lasso Regression for our dataset, as indicated by the lower MSE and MAE, and higher R-squared values.\n",
    "\n",
    "The similarity in performance between Linear and Ridge Regression suggests that the dataset might not have significant multicollinearity issues or that the effect of regularization in Ridge Regression is minimal at the chosen alpha value.\n",
    "\n",
    "Given these results, Linear or Ridge Regression may be the preferred model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f0522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
