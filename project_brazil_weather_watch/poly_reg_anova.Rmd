---
title: "141C Project"
author: "Alexander Kapustin"
date: "2024-01-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(corrplot)
library(caret)
library(purrr)
library(modelr)
library(glmnet)
```

```{r}
clean_set <- read.csv("/path/")
```

tPrec: This variable represents the amount of precipitation in millimetres (last hour)

atmosPStatn: This variable represents atmospheric pressure at a station in millibars (mb)

rad: This variable represents Solar radiation $\frac{KJ}{m^2}$

airTemp: This variable represents air temperature(instant) in $^\circ C$ *

dpTemp: This variable represents dew point temperature(instant) in $^\circ C$

prevHrMinTemp: This variable represents the previous hour's minimum temperature in $^\circ C$;

airHum: This variable represents air humidity(instant) in %

windDir: This variable represents wind direction in radius degrees ($0-360^\circ$)

windSp: This variable represents wind speed in meters per second

lat: This variable represents latitude

long: This variable represents longitude

(*) Variable of interest ($Y$)

tPrec, atmosPStatn, rad, dpTemp, prevHrMinTemp, airHum, windDir, windSp, lat, long

```{r}
# Function train = 70% test = 30%
split_group <- function(group) {
  # Sort vals in ascending order of date_time
  group <- group %>% arrange(date_time)
  # Non-random, ordered train-test split
  train_set <- group %>% slice(1:round(n() * 0.7))
  test_set <- group %>% slice((round(n() * 0.7) + 1):n())
  return(list(train_set, test_set))
}

# Group by lat and long
grouped_data <- clean_set %>% group_by(lat, long)
grouped_data <- as.data.frame(grouped_data)
train_test_sets <- grouped_data %>% group_modify(~split_group(.x))

# Train and Test sets
train_set <- bind_rows(train_test_sets[[1]])
train_set <- train_set %>% arrange(row_number()) # Reset row numbers
test_set <- bind_rows(train_test_sets[[2]])
test_set <- test_set %>% arrange(row_number())

X_train <- train_set %>% select(-airTemp)
y_train <- train_set$airTemp
X_test <- test_set %>% select(-airTemp)
y_test <- test_set$airTemp
```

## Determining the optimal polynomial degree for each predictor variable in the test set through the ANOVA approach

```{r}
poly_airHum1 <- lm(y_train ~ airHum, data = X_train)
poly_airHum2 <- lm(y_train ~ poly(airHum , 2), data = X_train)
poly_airHum3 <- lm(y_train ~ poly(airHum , 3), data = X_train)
poly_airHum4 <- lm(y_train ~ poly(airHum , 4), data = X_train)
poly_airHum5 <- lm(y_train ~ poly(airHum , 5), data = X_train)
anova(poly_airHum1, poly_airHum2, poly_airHum3, poly_airHum4, poly_airHum5)
```

## The variable "airHum," degrees 4 and 5 demonstrate the best performance, implying that degree 4 is preferable to avoid overfitting.

```{r}
poly_tPrec1 <- lm(y_train ~ tPrec, data = X_train)
poly_tPrec2 <- lm(y_train ~ poly(tPrec , 2), data = X_train)
poly_tPrec3 <- lm(y_train ~ poly(tPrec , 3), data = X_train)
poly_tPrec4 <- lm(y_train ~ poly(tPrec , 4), data = X_train)
poly_tPrec5 <- lm(y_train ~ poly(tPrec , 5), data = X_train)
anova(poly_tPrec1, poly_tPrec2, poly_tPrec3, poly_tPrec4, poly_tPrec5)
```

## The variable "tPrec" the RSS remains relatively similar from degrees 2 to 5, indicating that degree 2 should be selected to prevent overfitting;

```{r}
poly_atmosPStatn1 <- lm(y_train ~ atmosPStatn, data = X_train)
poly_atmosPStatn2 <- lm(y_train ~ poly(atmosPStatn , 2), data = X_train)
poly_atmosPStatn3 <- lm(y_train ~ poly(atmosPStatn , 3), data = X_train)
poly_atmosPStatn4 <- lm(y_train ~ poly(atmosPStatn , 4), data = X_train)
poly_atmosPStatn5 <- lm(y_train ~ poly(atmosPStatn , 5), data = X_train)
anova(poly_atmosPStatn1, poly_atmosPStatn2, poly_atmosPStatn3, poly_atmosPStatn4, poly_atmosPStatn5)
```

## The variable "atmosPStatn" the RSS remains relatively similar from degrees 2 to 5, indicating that degree 2 should be selected to prevent overfitting;

```{r}
poly_rad1 <- lm(y_train ~ rad, data = X_train)
poly_rad2 <- lm(y_train ~ poly(rad , 2), data = X_train)
poly_rad3 <- lm(y_train ~ poly(rad , 3), data = X_train)
poly_rad4 <- lm(y_train ~ poly(rad , 4), data = X_train)
poly_rad5 <- lm(y_train ~ poly(rad , 5), data = X_train)
anova(poly_rad1, poly_rad2, poly_rad3, poly_rad4, poly_rad5)
```

## The variable "rad," degrees 4 and 5 demonstrate the best performance, implying that degree 4 is preferable to avoid overfitting;

```{r}
poly_dpTemp1 <- lm(y_train ~ dpTemp, data = X_train)
poly_dpTemp2 <- lm(y_train ~ poly(dpTemp , 2), data = X_train)
poly_dpTemp3 <- lm(y_train ~ poly(dpTemp , 3), data = X_train)
poly_dpTemp4 <- lm(y_train ~ poly(dpTemp , 4), data = X_train)
poly_dpTemp5 <- lm(y_train ~ poly(dpTemp , 5), data = X_train)
anova(poly_dpTemp1, poly_dpTemp2, poly_dpTemp3, poly_dpTemp4, poly_dpTemp5)
```

## The variable "dpTemp" the RSS remains relatively constant from degrees 3 to 5, indicating that degree 3 should be selected to prevent overfitting;

```{r}
poly_prevHrMinTemp1 <- lm(y_train ~ prevHrMinTemp, data = X_train)
poly_prevHrMinTemp2 <- lm(y_train ~ poly(prevHrMinTemp , 2), data = X_train)
poly_prevHrMinTemp3 <- lm(y_train ~ poly(prevHrMinTemp , 3), data = X_train)
poly_prevHrMinTemp4 <- lm(y_train ~ poly(prevHrMinTemp , 4), data = X_train)
poly_prevHrMinTemp5 <- lm(y_train ~ poly(prevHrMinTemp , 5), data = X_train)
anova(poly_prevHrMinTemp1, poly_prevHrMinTemp2, poly_prevHrMinTemp3, poly_prevHrMinTemp4, poly_prevHrMinTemp5)
```

## The variable "prevHrMinTemp" doesn't exhibit significant changes across the 5 polynomial degrees as well, suggesting that degree 1 suffices;

```{r}
poly_windDir1 <- lm(y_train ~ windDir, data = X_train)
poly_windDir2 <- lm(y_train ~ poly(windDir , 2), data = X_train)
poly_windDir3 <- lm(y_train ~ poly(windDir , 3), data = X_train)
poly_windDir4 <- lm(y_train ~ poly(windDir , 4), data = X_train)
poly_windDir5 <- lm(y_train ~ poly(windDir , 5), data = X_train)
anova(poly_windDir1, poly_windDir2, poly_windDir3, poly_windDir4, poly_windDir5)
```

## The variable "windDir" the RSS remains relatively similar from degrees 3 to 5, indicating that degree 3 should be selected to prevent overfitting;

```{r}
poly_windSp1 <- lm(y_train ~ windSp, data = X_train)
poly_windSp2 <- lm(y_train ~ poly(windSp , 2), data = X_train)
poly_windSp3 <- lm(y_train ~ poly(windSp , 3), data = X_train)
poly_windSp4 <- lm(y_train ~ poly(windSp , 4), data = X_train)
poly_windSp5 <- lm(y_train ~ poly(windSp , 5), data = X_train)
anova(poly_windSp1, poly_windSp2, poly_windSp3, poly_windSp4, poly_windSp5)
```

## The variable "windSp" the RSS remains relatively similar from degrees 2 to 5, indicating that degree 2 should be selected to prevent overfitting;

```{r}
poly_lat1 <- lm(y_train ~ lat, data = X_train)
poly_lat2 <- lm(y_train ~ poly(lat , 2), data = X_train)
poly_lat3 <- lm(y_train ~ poly(lat , 3), data = X_train)
poly_lat4 <- lm(y_train ~ poly(lat , 4), data = X_train)
poly_lat5 <- lm(y_train ~ poly(lat , 5), data = X_train)
anova(poly_lat1, poly_lat2, poly_lat3, poly_lat4, poly_lat5)
```

## The variable "lat" doesn't exhibit significant changes across the 5 polynomial degrees, suggesting that degree 1 suffices;

```{r}
poly_long1 <- lm(y_train ~ long, data = X_train)
poly_long2 <- lm(y_train ~ poly(long , 2), data = X_train)
poly_long3 <- lm(y_train ~ poly(long , 3), data = X_train)
poly_long4 <- lm(y_train ~ poly(long , 4), data = X_train)
poly_long5 <- lm(y_train ~ poly(long , 5), data = X_train)
anova(poly_long1, poly_long2, poly_long3, poly_long4, poly_long5)
```
## The variable "long" doesn't exhibit significant changes across the 5 polynomial degrees as well, suggesting that degree 1 suffices;

```{r}
# Poly Regression Model
# airTemp ~ lat + long + prevHrMinTemp + tPrec^2 + atmosPStatn^2 + windSp^2 + windDir^3 + dpTemp^3 + airHum^4 + rad^4
poly_final <- lm(y_train ~ poly(lat, 1) + poly(long, 1) + 
                  poly(tPrec, 2) + poly(atmosPStatn, 2) + poly(windSp, 2) + 
                  poly(windDir, 3) + poly(dpTemp, 3) + poly(airHum, 4) + poly(rad, 4), 
                data = X_train)
summary(poly_final)
#+ poly(prevHrMinTemp, 1) 
```

```{r}
# Predictions for the test set using the poly regression model
test_predictions <- predict(poly_final, newdata = X_test)
# Accuracy of the model on the test set
test_accuracy <- sqrt(mean((y_test - test_predictions)^2))
mean_y_test <- mean(y_test)
paste("The model's predictions are off by ", (test_accuracy/mean_y_test)*100, "%")
```
This percentage error seems quite low, suggesting that the model's predictions are relatively close to the actual values in the test set, which is a really good sign of the model's performance.

```{r}
# MSE
mse <- mean((y_test - test_predictions)^2)
# MAE
mae <- mean(abs(y_test - test_predictions))

paste("The Mean Squared Error for the model is: ", mse)
paste("The Mean Absolute Error for the model is: ", mae)
```